{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Modeling Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In this notebook I explore the different baseline models and ensemble methods. I decided to use the most common classification models as basic initial models, using Accuracy score as the main scoring metric, Recall since we want to minimize the False Positive predictions so the company does not focuses on customers that may not churn and F1 to look at the overall model score.\n",
    "\n",
    "Since we want to make sure that each model predicts with the best accuracy to prevent any loss of attention or revenue on customers that are not recurrent churners or are possible to churn.\n",
    "\n",
    "I am also using Cross Validation to see how each model reacts to data that has not been used in modeling. Cross Validation is scored by looking at the minimum score and the maximum score, the mean of all scores and the range. In my scoring, the lower the range the better the model performs to unseen data. Min and Max are utilized just as markers to how poor and how well the model performed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T17:45:59.310552Z",
     "start_time": "2021-01-02T17:45:57.695293Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import neighbors\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pd.set_option('display.max_columns', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T17:45:59.395507Z",
     "start_time": "2021-01-02T17:45:59.312717Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"modeling_customer_df.csv\",index_col=\"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T17:45:59.482059Z",
     "start_time": "2021-01-02T17:45:59.398492Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>senior_citizen</th>\n",
       "      <th>partner</th>\n",
       "      <th>dependents</th>\n",
       "      <th>tenure_months</th>\n",
       "      <th>phone_service</th>\n",
       "      <th>device_protection</th>\n",
       "      <th>tech_support</th>\n",
       "      <th>paperless_billing</th>\n",
       "      <th>monthly_charges</th>\n",
       "      <th>cltv</th>\n",
       "      <th>satisfaction_score</th>\n",
       "      <th>referred_a_friend</th>\n",
       "      <th>number_of_referrals</th>\n",
       "      <th>tenure_in_months</th>\n",
       "      <th>avg_monthly_long_distance_charges</th>\n",
       "      <th>avg_monthly_gb_download</th>\n",
       "      <th>device_protection_plan</th>\n",
       "      <th>premium_tech_support</th>\n",
       "      <th>streaming_music</th>\n",
       "      <th>unlimited_data</th>\n",
       "      <th>total_refunds</th>\n",
       "      <th>total_extra_data_charges</th>\n",
       "      <th>total_long_distance_charges</th>\n",
       "      <th>total_revenue</th>\n",
       "      <th>under_30</th>\n",
       "      <th>number_of_dependents</th>\n",
       "      <th>tel_internet_service</th>\n",
       "      <th>tel_online_securit</th>\n",
       "      <th>tel_online_backup</th>\n",
       "      <th>tel_multiple_lines</th>\n",
       "      <th>tel_streaming_tv</th>\n",
       "      <th>tel_total_charges</th>\n",
       "      <th>tel_streaming_movies</th>\n",
       "      <th>cit_Adelanto</th>\n",
       "      <th>cit_Anaheim</th>\n",
       "      <th>cit_Apple Valley</th>\n",
       "      <th>cit_Bakersfield</th>\n",
       "      <th>cit_Brea</th>\n",
       "      <th>cit_Cerritos</th>\n",
       "      <th>cit_Chula Vista</th>\n",
       "      <th>cit_Concord</th>\n",
       "      <th>cit_Crescent Mills</th>\n",
       "      <th>cit_El Monte</th>\n",
       "      <th>cit_Elk Grove</th>\n",
       "      <th>cit_Fremont</th>\n",
       "      <th>cit_Fresno</th>\n",
       "      <th>cit_Glendale</th>\n",
       "      <th>cit_Hayward</th>\n",
       "      <th>cit_Huntington Beach</th>\n",
       "      <th>cit_Inglewood</th>\n",
       "      <th>cit_Irvine</th>\n",
       "      <th>cit_Lakewood</th>\n",
       "      <th>cit_Lancaster</th>\n",
       "      <th>cit_Lompoc</th>\n",
       "      <th>cit_Long Beach</th>\n",
       "      <th>cit_Los Angeles</th>\n",
       "      <th>cit_Modesto</th>\n",
       "      <th>cit_Mountain View</th>\n",
       "      <th>cit_Oakland</th>\n",
       "      <th>cit_Pasadena</th>\n",
       "      <th>cit_Riverside</th>\n",
       "      <th>cit_Sacramento</th>\n",
       "      <th>cit_San Bernardino</th>\n",
       "      <th>cit_San Diego</th>\n",
       "      <th>cit_San Dimas</th>\n",
       "      <th>cit_San Francisco</th>\n",
       "      <th>cit_San Jose</th>\n",
       "      <th>cit_Santa Barbara</th>\n",
       "      <th>cit_Santa Monica</th>\n",
       "      <th>cit_Santa Rosa</th>\n",
       "      <th>cit_Smith River</th>\n",
       "      <th>cit_Stockton</th>\n",
       "      <th>cit_Sun City</th>\n",
       "      <th>cit_Temecula</th>\n",
       "      <th>cit_Whittier</th>\n",
       "      <th>zip_code_90623</th>\n",
       "      <th>zip_code_91010</th>\n",
       "      <th>zip_code_91206</th>\n",
       "      <th>zip_code_91762</th>\n",
       "      <th>zip_code_93245</th>\n",
       "      <th>zip_code_93702</th>\n",
       "      <th>zip_code_93711</th>\n",
       "      <th>zip_code_94027</th>\n",
       "      <th>zip_code_94520</th>\n",
       "      <th>latitude_33.8681</th>\n",
       "      <th>latitude_34.162515</th>\n",
       "      <th>latitude_36.739385</th>\n",
       "      <th>longitude_-121.55325</th>\n",
       "      <th>longitude_-120.653519</th>\n",
       "      <th>longitude_-119.82947</th>\n",
       "      <th>longitude_-118.24902</th>\n",
       "      <th>longitude_-118.203869</th>\n",
       "      <th>longitude_-117.815532</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>offer_Offer A</th>\n",
       "      <th>offer_Offer B</th>\n",
       "      <th>offer_Offer C</th>\n",
       "      <th>offer_Offer D</th>\n",
       "      <th>offer_Offer E</th>\n",
       "      <th>internet_type_DSL</th>\n",
       "      <th>internet_type_Fiber Optic</th>\n",
       "      <th>internet_type_None</th>\n",
       "      <th>age_20</th>\n",
       "      <th>age_30</th>\n",
       "      <th>age_40</th>\n",
       "      <th>age_50</th>\n",
       "      <th>age_60</th>\n",
       "      <th>age_70</th>\n",
       "      <th>tel_payment_method_Credit Card</th>\n",
       "      <th>tel_payment_method_Mailed Check</th>\n",
       "      <th>tel_contract_One Year</th>\n",
       "      <th>tel_contract_Two Year</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.85</td>\n",
       "      <td>3239.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.47</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.94</td>\n",
       "      <td>129.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>108.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.70</td>\n",
       "      <td>2701.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.12</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.24</td>\n",
       "      <td>169.89</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>151.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.65</td>\n",
       "      <td>5372.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.15</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.20</td>\n",
       "      <td>917.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>820.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>104.80</td>\n",
       "      <td>5003.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>4.89</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>136.92</td>\n",
       "      <td>3182.97</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3046.05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>103.70</td>\n",
       "      <td>5340.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>44.33</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2172.17</td>\n",
       "      <td>7208.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5036.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   senior_citizen  partner  dependents  tenure_months  phone_service  \\\n",
       "0             0.0      0.0         0.0            2.0            1.0   \n",
       "1             0.0      0.0         1.0            2.0            1.0   \n",
       "2             0.0      0.0         1.0            8.0            1.0   \n",
       "3             0.0      1.0         1.0           28.0            1.0   \n",
       "4             0.0      0.0         1.0           49.0            1.0   \n",
       "\n",
       "   device_protection  tech_support  paperless_billing  monthly_charges  \\\n",
       "0                0.0           0.0                1.0            53.85   \n",
       "1                0.0           0.0                1.0            70.70   \n",
       "2                1.0           0.0                1.0            99.65   \n",
       "3                1.0           1.0                1.0           104.80   \n",
       "4                1.0           0.0                1.0           103.70   \n",
       "\n",
       "     cltv  satisfaction_score  referred_a_friend  number_of_referrals  \\\n",
       "0  3239.0                 1.0                0.0                  0.0   \n",
       "1  2701.0                 2.0                0.0                  0.0   \n",
       "2  5372.0                 3.0                0.0                  0.0   \n",
       "3  5003.0                 3.0                0.0                  0.0   \n",
       "4  5340.0                 1.0                0.0                  0.0   \n",
       "\n",
       "   tenure_in_months  avg_monthly_long_distance_charges  \\\n",
       "0               2.0                              10.47   \n",
       "1               2.0                               9.12   \n",
       "2               8.0                              12.15   \n",
       "3              28.0                               4.89   \n",
       "4              49.0                              44.33   \n",
       "\n",
       "   avg_monthly_gb_download  device_protection_plan  premium_tech_support  \\\n",
       "0                     21.0                     0.0                   0.0   \n",
       "1                     51.0                     0.0                   0.0   \n",
       "2                     26.0                     1.0                   0.0   \n",
       "3                     47.0                     1.0                   1.0   \n",
       "4                     11.0                     1.0                   0.0   \n",
       "\n",
       "   streaming_music  unlimited_data  total_refunds  total_extra_data_charges  \\\n",
       "0              0.0             1.0            0.0                       0.0   \n",
       "1              0.0             1.0            0.0                       0.0   \n",
       "2              1.0             1.0            0.0                       0.0   \n",
       "3              1.0             1.0            0.0                       0.0   \n",
       "4              1.0             1.0            0.0                       0.0   \n",
       "\n",
       "   total_long_distance_charges  total_revenue  under_30  number_of_dependents  \\\n",
       "0                        20.94         129.09       0.0                   0.0   \n",
       "1                        18.24         169.89       1.0                   2.0   \n",
       "2                        97.20         917.70       0.0                   2.0   \n",
       "3                       136.92        3182.97       1.0                   3.0   \n",
       "4                      2172.17        7208.47       0.0                   1.0   \n",
       "\n",
       "   tel_internet_service  tel_online_securit  tel_online_backup  \\\n",
       "0                   1.0                 1.0                1.0   \n",
       "1                   1.0                 0.0                0.0   \n",
       "2                   1.0                 0.0                0.0   \n",
       "3                   1.0                 0.0                0.0   \n",
       "4                   1.0                 0.0                1.0   \n",
       "\n",
       "   tel_multiple_lines  tel_streaming_tv  tel_total_charges  \\\n",
       "0                 0.0               0.0             108.15   \n",
       "1                 0.0               0.0             151.65   \n",
       "2                 1.0               1.0             820.50   \n",
       "3                 1.0               1.0            3046.05   \n",
       "4                 1.0               1.0            5036.30   \n",
       "\n",
       "   tel_streaming_movies  cit_Adelanto  cit_Anaheim  cit_Apple Valley  \\\n",
       "0                   0.0           0.0          0.0               0.0   \n",
       "1                   0.0           0.0          0.0               0.0   \n",
       "2                   1.0           0.0          0.0               0.0   \n",
       "3                   1.0           0.0          0.0               0.0   \n",
       "4                   1.0           0.0          0.0               0.0   \n",
       "\n",
       "   cit_Bakersfield  cit_Brea  cit_Cerritos  cit_Chula Vista  cit_Concord  \\\n",
       "0              0.0       0.0           0.0              0.0          0.0   \n",
       "1              0.0       0.0           0.0              0.0          0.0   \n",
       "2              0.0       0.0           0.0              0.0          0.0   \n",
       "3              0.0       0.0           0.0              0.0          0.0   \n",
       "4              0.0       0.0           0.0              0.0          0.0   \n",
       "\n",
       "   cit_Crescent Mills  cit_El Monte  cit_Elk Grove  cit_Fremont  cit_Fresno  \\\n",
       "0                 0.0           0.0            0.0          0.0         0.0   \n",
       "1                 0.0           0.0            0.0          0.0         0.0   \n",
       "2                 0.0           0.0            0.0          0.0         0.0   \n",
       "3                 0.0           0.0            0.0          0.0         0.0   \n",
       "4                 0.0           0.0            0.0          0.0         0.0   \n",
       "\n",
       "   cit_Glendale  cit_Hayward  cit_Huntington Beach  cit_Inglewood  cit_Irvine  \\\n",
       "0           0.0          0.0                   0.0            0.0         0.0   \n",
       "1           0.0          0.0                   0.0            0.0         0.0   \n",
       "2           0.0          0.0                   0.0            0.0         0.0   \n",
       "3           0.0          0.0                   0.0            0.0         0.0   \n",
       "4           0.0          0.0                   0.0            0.0         0.0   \n",
       "\n",
       "   cit_Lakewood  cit_Lancaster  cit_Lompoc  cit_Long Beach  cit_Los Angeles  \\\n",
       "0           0.0            0.0         0.0             0.0              1.0   \n",
       "1           0.0            0.0         0.0             0.0              1.0   \n",
       "2           0.0            0.0         0.0             0.0              1.0   \n",
       "3           0.0            0.0         0.0             0.0              1.0   \n",
       "4           0.0            0.0         0.0             0.0              1.0   \n",
       "\n",
       "   cit_Modesto  cit_Mountain View  cit_Oakland  cit_Pasadena  cit_Riverside  \\\n",
       "0          0.0                0.0          0.0           0.0            0.0   \n",
       "1          0.0                0.0          0.0           0.0            0.0   \n",
       "2          0.0                0.0          0.0           0.0            0.0   \n",
       "3          0.0                0.0          0.0           0.0            0.0   \n",
       "4          0.0                0.0          0.0           0.0            0.0   \n",
       "\n",
       "   cit_Sacramento  cit_San Bernardino  cit_San Diego  cit_San Dimas  \\\n",
       "0             0.0                 0.0            0.0            0.0   \n",
       "1             0.0                 0.0            0.0            0.0   \n",
       "2             0.0                 0.0            0.0            0.0   \n",
       "3             0.0                 0.0            0.0            0.0   \n",
       "4             0.0                 0.0            0.0            0.0   \n",
       "\n",
       "   cit_San Francisco  cit_San Jose  cit_Santa Barbara  cit_Santa Monica  \\\n",
       "0                0.0           0.0                0.0               0.0   \n",
       "1                0.0           0.0                0.0               0.0   \n",
       "2                0.0           0.0                0.0               0.0   \n",
       "3                0.0           0.0                0.0               0.0   \n",
       "4                0.0           0.0                0.0               0.0   \n",
       "\n",
       "   cit_Santa Rosa  cit_Smith River  cit_Stockton  cit_Sun City  cit_Temecula  \\\n",
       "0             0.0              0.0           0.0           0.0           0.0   \n",
       "1             0.0              0.0           0.0           0.0           0.0   \n",
       "2             0.0              0.0           0.0           0.0           0.0   \n",
       "3             0.0              0.0           0.0           0.0           0.0   \n",
       "4             0.0              0.0           0.0           0.0           0.0   \n",
       "\n",
       "   cit_Whittier  zip_code_90623  zip_code_91010  zip_code_91206  \\\n",
       "0           0.0             0.0             0.0             0.0   \n",
       "1           0.0             0.0             0.0             0.0   \n",
       "2           0.0             0.0             0.0             0.0   \n",
       "3           0.0             0.0             0.0             0.0   \n",
       "4           0.0             0.0             0.0             0.0   \n",
       "\n",
       "   zip_code_91762  zip_code_93245  zip_code_93702  zip_code_93711  \\\n",
       "0             0.0             0.0             0.0             0.0   \n",
       "1             0.0             0.0             0.0             0.0   \n",
       "2             0.0             0.0             0.0             0.0   \n",
       "3             0.0             0.0             0.0             0.0   \n",
       "4             0.0             0.0             0.0             0.0   \n",
       "\n",
       "   zip_code_94027  zip_code_94520  latitude_33.8681  latitude_34.162515  \\\n",
       "0             0.0             0.0               0.0                 0.0   \n",
       "1             0.0             0.0               0.0                 0.0   \n",
       "2             0.0             0.0               0.0                 0.0   \n",
       "3             0.0             0.0               0.0                 0.0   \n",
       "4             0.0             0.0               0.0                 0.0   \n",
       "\n",
       "   latitude_36.739385  longitude_-121.55325  longitude_-120.653519  \\\n",
       "0                 0.0                   0.0                    0.0   \n",
       "1                 0.0                   0.0                    0.0   \n",
       "2                 0.0                   0.0                    0.0   \n",
       "3                 0.0                   0.0                    0.0   \n",
       "4                 0.0                   0.0                    0.0   \n",
       "\n",
       "   longitude_-119.82947  longitude_-118.24902  longitude_-118.203869  \\\n",
       "0                   0.0                   0.0                    0.0   \n",
       "1                   0.0                   0.0                    0.0   \n",
       "2                   0.0                   0.0                    0.0   \n",
       "3                   0.0                   0.0                    0.0   \n",
       "4                   0.0                   0.0                    0.0   \n",
       "\n",
       "   longitude_-117.815532  gender_Male  offer_Offer A  offer_Offer B  \\\n",
       "0                    0.0          1.0            0.0            0.0   \n",
       "1                    0.0          0.0            0.0            0.0   \n",
       "2                    0.0          0.0            0.0            0.0   \n",
       "3                    0.0          0.0            0.0            0.0   \n",
       "4                    0.0          1.0            0.0            0.0   \n",
       "\n",
       "   offer_Offer C  offer_Offer D  offer_Offer E  internet_type_DSL  \\\n",
       "0            0.0            0.0            0.0                1.0   \n",
       "1            0.0            0.0            0.0                0.0   \n",
       "2            0.0            0.0            0.0                0.0   \n",
       "3            1.0            0.0            0.0                0.0   \n",
       "4            0.0            0.0            0.0                0.0   \n",
       "\n",
       "   internet_type_Fiber Optic  internet_type_None  age_20  age_30  age_40  \\\n",
       "0                        0.0                 0.0     0.0     1.0     0.0   \n",
       "1                        1.0                 0.0     0.0     0.0     0.0   \n",
       "2                        0.0                 0.0     0.0     1.0     0.0   \n",
       "3                        1.0                 0.0     1.0     0.0     0.0   \n",
       "4                        1.0                 0.0     0.0     1.0     0.0   \n",
       "\n",
       "   age_50  age_60  age_70  tel_payment_method_Credit Card  \\\n",
       "0     0.0     0.0     0.0                             1.0   \n",
       "1     0.0     0.0     0.0                             0.0   \n",
       "2     0.0     0.0     0.0                             0.0   \n",
       "3     0.0     0.0     0.0                             0.0   \n",
       "4     0.0     0.0     0.0                             0.0   \n",
       "\n",
       "   tel_payment_method_Mailed Check  tel_contract_One Year  \\\n",
       "0                              0.0                    0.0   \n",
       "1                              0.0                    0.0   \n",
       "2                              0.0                    0.0   \n",
       "3                              0.0                    0.0   \n",
       "4                              0.0                    0.0   \n",
       "\n",
       "   tel_contract_Two Year    y  \n",
       "0                    0.0  1.0  \n",
       "1                    0.0  1.0  \n",
       "2                    0.0  1.0  \n",
       "3                    0.0  1.0  \n",
       "4                    0.0  1.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T17:45:59.491932Z",
     "start_time": "2021-01-02T17:45:59.484594Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Splitting the data into X and Y\n",
    "y=df[\"y\"]\n",
    "X=df.drop([\"y\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Vanilla Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "I am using several classification models like Logistic Regression, KNN, RandomForest and also boosted models such as XGBoost and GradientBoost. KNN and RandomForest were selected to test if the data is able to be classified aggregately but the goal is to find a model that is able to be interpreted and could benefit the company in seeing what factors can affect a customer churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T17:45:59.502987Z",
     "start_time": "2021-01-02T17:45:59.493358Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Creating Train Test Split.\n",
    "X_test,X_train,y_test,y_train=train_test_split(X,y, test_size=.2, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T17:45:59.523810Z",
     "start_time": "2021-01-02T17:45:59.504432Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#this function was created to visualize scores and create a dataframe with each score.\n",
    "def scoring(preds , model_name: str,model, cv=10, xtrain=X_train):\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    \"\"\"\n",
    "    The function statrts by returning the training scores of the model then, it takes in predictions of the\n",
    "    model, model, model name, and times that model will be cross validated and returns the Accuracy, \n",
    "    Recall, F1 score and the CV Min, Max, Mean and Range scores based on accuracy.\n",
    "    \n",
    "    The function also creates a DF that saves all the infomation into a dataframe, making changes globaly. \n",
    "    \"\"\"\n",
    "    model.verbose=False\n",
    "    def warn(*args, **kwargs):\n",
    "        pass\n",
    "    import warnings\n",
    "    warnings.warn = warn\n",
    "    \n",
    "    if \"scores_df\" not in globals():\n",
    "        global scores_df \n",
    "        scores_df = pd.DataFrame(columns=[\"Name\",\"Accuracy\",\"Recall\",\"F1\",\"CV Min\",\"CV Max\",\"CV Mean\",\"CV Range\"])\n",
    "        \n",
    "    if \"scores_df\" in globals():\n",
    "        \n",
    "        if \"Grid\"in(model_name).split():\n",
    "            \n",
    "            model.verbose=False\n",
    "            print (\"Training Accuracy: {}\".format(metrics.accuracy_score(y_train, model.best_estimator_.predict(xtrain))))\n",
    "            print (\"Training Recall: {}\".format(metrics.recall_score(y_train, model.best_estimator_.predict(xtrain))))\n",
    "            print (\"Training F1: {}\".format(metrics.f1_score(y_train, model.best_estimator_.predict(xtrain))))\n",
    "\n",
    "            vars()[model_name+\"_recc\"]=metrics.recall_score(y_test, preds)\n",
    "            vars()[model_name+\"_acc\"]=metrics.accuracy_score(y_test, preds)\n",
    "            vars()[model_name+\"_f1\"]=metrics.f1_score(y_test,preds)\n",
    "\n",
    "            print(\"\\n\"+model_name+\" Accuracy: {}\".format(vars()[model_name+\"_acc\"]))\n",
    "            print(model_name+\" Recall: {}\".format(vars()[model_name+\"_recc\"]))\n",
    "            print(model_name+\" F1: {}\".format(vars()[model_name+\"_f1\"]))\n",
    "            def warn(*args, **kwargs):\n",
    "                pass\n",
    "                \n",
    "            import warnings\n",
    "            warnings.warn = warn\n",
    "\n",
    "\n",
    "            scores = cross_val_score(model.best_estimator_, xtrain, y_train, cv=cv)\n",
    "\n",
    "            print(\"\\nCross-Validation ({} times) Accuracy Scores:\".format(cv))    \n",
    "            print('Min: ', round(scores.min(), 6),'  Max: ', round(scores.max(), 6),'  Mean: ', round(scores.mean(), 6), '  Range: ', round(scores.max() - scores.min(), 6))\n",
    "\n",
    "        else:\n",
    "            \n",
    "            model.verbose=False\n",
    "            print (\"Training Accuracy: {}\".format(metrics.accuracy_score(y_train, model.predict(xtrain))))\n",
    "            print (\"Training Recall: {}\".format(metrics.recall_score(y_train, model.predict(xtrain))))\n",
    "            print (\"Training F1: {}\".format(metrics.f1_score(y_train, model.predict(xtrain))))\n",
    "\n",
    "            vars()[model_name+\"_recc\"]=metrics.recall_score(y_test, preds)\n",
    "            vars()[model_name+\"_acc\"]=metrics.accuracy_score(y_test, preds)\n",
    "            vars()[model_name+\"_f1\"]=metrics.f1_score(y_test,preds)\n",
    "\n",
    "            print(\"\\n\"+model_name+\" Accuracy: {}\".format(vars()[model_name+\"_acc\"]))\n",
    "            print(model_name+\" Recall: {}\".format(vars()[model_name+\"_recc\"]))\n",
    "            print(model_name+\" F1: {}\".format(vars()[model_name+\"_f1\"]))\n",
    "\n",
    "            def warn(*args, **kwargs):\n",
    "                pass\n",
    "                \n",
    "            import warnings\n",
    "            warnings.warn = warn\n",
    "\n",
    "            scores = cross_val_score(model,xtrain , y_train, cv=cv, verbose=False)\n",
    "\n",
    "            print(\"\\nCross-Validation ({} times) Accuracy Scores:\".format(cv))    \n",
    "            print('Min: ', round(scores.min(), 6),'  Max: ', round(scores.max(), 6),'  Mean: ', round(scores.mean(), 6), '  Range: ', round(scores.max() - scores.min(), 6))\n",
    "\n",
    "\n",
    "        if model_name not in list(scores_df.Name):\n",
    "            \n",
    "            scores_df=scores_df.append({'Name':model_name, \"Accuracy\":vars()[model_name+\"_acc\"] , \"Recall\": vars()[model_name+\"_recc\"],\"F1\":vars()[model_name+\"_f1\"],\"CV Min\":scores.min() ,\"CV Max\":scores.max(),\"CV Mean\":scores.mean(), \"CV Range\": (scores.max() - scores.min())}, ignore_index=True)\n",
    "    \n",
    "        else:\n",
    "            i=list(scores_df[scores_df.Name==model_name].index)\n",
    "            scores_df.drop(scores_df.index[i], inplace=True) \n",
    "            scores_df=scores_df.append({'Name':model_name, \"Accuracy\":vars()[model_name+\"_acc\"] , \"Recall\": vars()[model_name+\"_recc\"],\"F1\":vars()[model_name+\"_f1\"],\"CV Min\":scores.min() ,\"CV Max\":scores.max(),\"CV Mean\":scores.mean(), \"CV Range\": (scores.max() - scores.min())}, ignore_index=True)\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "I decided to start with Logistic Regression since its a model that is very easy to interpret and can also be tunned quite easily. \n",
    "\n",
    "* The model is tunned by setting max iterations to 100000 since we want the model to converge.\n",
    "* Random State of 40 is maintained in all the models for continuity.\n",
    "* Class Weight Balanced is used, since there is a class imbalance with the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T17:45:59.528943Z",
     "start_time": "2021-01-02T17:45:59.526365Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Instantiating Logistic Regression with Max Iter of 10000 so the model can reach convergence\n",
    "log_reg=LogisticRegression(max_iter=100000, random_state=40, class_weight=\"balanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T17:46:02.916459Z",
     "start_time": "2021-01-02T17:45:59.532038Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Fitting and predicting results.\n",
    "log_reg.fit(X_train,y_train)\n",
    "\n",
    "log_pred=log_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T17:46:23.217688Z",
     "start_time": "2021-01-02T17:46:02.919969Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9616749467707594\n",
      "Training Recall: 0.9742120343839542\n",
      "Training F1: 0.9264305177111716\n",
      "\n",
      "Logistic Rregression Accuracy: 0.9439119630812921\n",
      "Logistic Rregression Recall: 0.9407894736842105\n",
      "Logistic Rregression F1: 0.9005037783375315\n",
      "\n",
      "Cross-Validation (5 times) Accuracy Scores:\n",
      "Min:  0.939502   Max:  0.968085   Mean:  0.949602   Range:  0.028583\n"
     ]
    }
   ],
   "source": [
    "# Scoring function used to see the results. \n",
    "scoring(log_pred , \"Logistic Rregression\", log_reg, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This model has performed with great results. The Accuracy and Recall have high scores that shows that the model is doing a great job at classifying the data.\n",
    "\n",
    "CV maintain similar scores to the ones resulted from the modeling step. With a range of 0.02 shows that there is little change when the model is exposed to new data and that there is very few issues at classifying. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "I decided to use KNN since it want to see if the data is able to be predicted by neighboring features. I want to use a K of 10 since using a low K could not be helpful at creating decision lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T17:46:23.222370Z",
     "start_time": "2021-01-02T17:46:23.219789Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# instantiating KNN with a N Neighbors of 10 as baseline.\n",
    "knn=KNeighborsClassifier(n_neighbors=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T17:46:23.553987Z",
     "start_time": "2021-01-02T17:46:23.224798Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Fitting and predicting\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "knn_pred=knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T17:46:23.935074Z",
     "start_time": "2021-01-02T17:46:23.556133Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.7771469127040455\n",
      "Training Recall: 0.20630372492836677\n",
      "Training F1: 0.314410480349345\n",
      "\n",
      "KNN Accuracy: 0.7255946041888534\n",
      "KNN Recall: 0.1256578947368421\n",
      "KNN F1: 0.19813278008298757\n",
      "\n",
      "Cross-Validation (5 times) Accuracy Scores:\n",
      "Min:  0.72695   Max:  0.765125   Mean:  0.743805   Range:  0.038174\n"
     ]
    }
   ],
   "source": [
    "# Scoring function used to view results.\n",
    "scoring(knn_pred , \"KNN\", knn, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The model performed terribly. The training scores show that the model is not good at understanding the data. The testing scores show that the model is unable to classify each prediction. with a Recall so low and F1 of similar value, this model is not a model that I can pursue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "I continued with Random Forest. Although Random Forest is not an interpretable model, it should be explored. the model was tuned using:\n",
    "\n",
    "* Max Depth of 5 since we do not want the model to overfit the training data.\n",
    "* Class Weight \"Balanced\" is used since the data is not balanced and we want to mitigate that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T17:46:23.940553Z",
     "start_time": "2021-01-02T17:46:23.937397Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Instantiating Random Fores with a max depth of 20 so the model has enough room to grow. \n",
    "RF=RandomForestClassifier(max_depth=5,verbose=True, random_state=40,class_weight=\"balanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T17:46:24.147092Z",
     "start_time": "2021-01-02T17:46:23.943113Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "RF.fit(X_train,y_train)\n",
    "\n",
    "rf_pred=RF.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T17:46:25.018021Z",
     "start_time": "2021-01-02T17:46:24.149394Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9325762952448545\n",
      "Training Recall: 0.9369627507163324\n",
      "Training F1: 0.8731642189586115\n",
      "\n",
      "Random Forest Accuracy: 0.9185303514376997\n",
      "Random Forest Recall: 0.9243421052631579\n",
      "Random Forest F1: 0.8595900887121444\n",
      "\n",
      "Cross-Validation (5 times) Accuracy Scores:\n",
      "Min:  0.900709   Max:  0.925532   Mean:  0.913412   Range:  0.024823\n"
     ]
    }
   ],
   "source": [
    "scoring(rf_pred , \"Random Forest\", RF, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The results of this model are better than what I got from KNN but not as great as Logistic Regression. The model has great results for our training scores, although training F1 as well as the testing F1 is not too great. The Accuracy in both training and test scores has a really great score and with the Cross Validation, we are able to see that the model trained very well since the Min and Max scores are close to the final score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Boosted Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "After trying basic models, I wanted to explore boosted models to see if there is better models to explore further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "I decided to explore XGBoost since its highly efficient and flexible. Since it implements machine learning algorithms under the Gradient Boosting framework. The tunning parameters that were used are:\n",
    "* Use Label Encoder False since all the data is already in integer values. \n",
    "* Objective \"Binary:Logistic\" since we are predicting a categorical target. \n",
    "* Evaluation Metric \"Logloss\" afterall, we want to measure how likely did the model think the actually observed set of outcomes was.\n",
    "* Learning rate of 2, since we want to make it easier at reaching the best optimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T17:46:25.023777Z",
     "start_time": "2021-01-02T17:46:25.020540Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "XGB = XGBClassifier(use_label_encoder=False, objective = \"binary:logistic\", eval_metric = \"logloss\", learning_rate = 2, random_state=40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T17:46:25.166224Z",
     "start_time": "2021-01-02T17:46:25.025900Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, eval_metric='logloss',\n",
       "              gamma=0, gpu_id=-1, importance_type='gain',\n",
       "              interaction_constraints='', learning_rate=2, max_delta_step=0,\n",
       "              max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
       "              num_parallel_tree=1, random_state=40, reg_alpha=0, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method='exact',\n",
       "              use_label_encoder=False, validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T17:46:25.187832Z",
     "start_time": "2021-01-02T17:46:25.168403Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xg_pred = XGB.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T17:46:25.934390Z",
     "start_time": "2021-01-02T17:46:25.189979Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.0\n",
      "Training Recall: 1.0\n",
      "Training F1: 1.0\n",
      "\n",
      "XGBoost Accuracy: 0.9416045438409656\n",
      "XGBoost Recall: 0.881578947368421\n",
      "XGBoost F1: 0.8906613492854769\n",
      "\n",
      "Cross-Validation (5 times) Accuracy Scores:\n",
      "Min:  0.911348   Max:  0.950355   Mean:  0.933987   Range:  0.039007\n"
     ]
    }
   ],
   "source": [
    "scoring(xg_pred , \"XGBoost\", XGB, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T17:46:25.939377Z",
     "start_time": "2021-01-02T17:46:25.936950Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# scores_df #Uncomment to view table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In the end, this model performed pretty great. The Accuracy and Recall are good scores, after the CV the model has a very low range meaning that the values are within thee expected output of the model. The downside is that the model is overfitting to the training set. This is not something ideal for any future data that will be passed on the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Gradient Boost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Lastly I want to explore Gradient Boost. Gradient Boost is the basis of XGBoost and works similarly to Logistic Regression. In the end I want a more interpretable model for the company to see what factors are affecting the churn of customers. \n",
    "\n",
    "The parameters used for Gradient Boost are:\n",
    "* N Estimators of 100 since we need the model to be able to converge. \n",
    "* Learning Rate of 5 maintaining a low learning rate we can assure the model would reach the optimum value.\n",
    "* Max Depth of 4 this penalty is used to make sure the model does not overfit to the data.\n",
    "* Criterion as \"Mean Square Error\" is used to measure the quality of a split.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T17:46:25.946585Z",
     "start_time": "2021-01-02T17:46:25.942459Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "reg = GradientBoostingClassifier(n_estimators=100, learning_rate=5.0, max_depth=4.0, criterion=\"mse\", random_state=40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T17:46:26.440213Z",
     "start_time": "2021-01-02T17:46:25.950178Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='mse', learning_rate=5.0, max_depth=4.0,\n",
       "                           random_state=40)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T17:46:26.471067Z",
     "start_time": "2021-01-02T17:46:26.447774Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "reg_pred=reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T17:46:28.889498Z",
     "start_time": "2021-01-02T17:46:26.476742Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.6919801277501775\n",
      "Training Recall: 0.9283667621776505\n",
      "Training F1: 0.5988909426987061\n",
      "\n",
      "Gradient Boost Accuracy: 0.6732339368122116\n",
      "Gradient Boost Recall: 0.905921052631579\n",
      "Gradient Boost F1: 0.5993471164309031\n",
      "\n",
      "Cross-Validation (5 times) Accuracy Scores:\n",
      "Min:  0.450355   Max:  0.879433   Mean:  0.72745   Range:  0.429078\n"
     ]
    }
   ],
   "source": [
    "scoring(reg_pred , \"Gradient Boost\", reg, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T17:46:28.893548Z",
     "start_time": "2021-01-02T17:46:28.891600Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# scores_df #Uncomment to view table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In the end this model did not perform as expected. The scores are all over the place, a very high Recall, very low Accuracy and F1 and the scores are similar on the training and test set. Looking at the CV, the range is the highest of all the models tried so far. But this indicates that the model after tunning could yield a really good model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T17:46:28.904365Z",
     "start_time": "2021-01-02T17:46:28.895270Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>CV Min</th>\n",
       "      <th>CV Max</th>\n",
       "      <th>CV Mean</th>\n",
       "      <th>CV Range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Rregression</td>\n",
       "      <td>0.943912</td>\n",
       "      <td>0.940789</td>\n",
       "      <td>0.900504</td>\n",
       "      <td>0.939502</td>\n",
       "      <td>0.968085</td>\n",
       "      <td>0.949602</td>\n",
       "      <td>0.028583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.725595</td>\n",
       "      <td>0.125658</td>\n",
       "      <td>0.198133</td>\n",
       "      <td>0.726950</td>\n",
       "      <td>0.765125</td>\n",
       "      <td>0.743805</td>\n",
       "      <td>0.038174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.918530</td>\n",
       "      <td>0.924342</td>\n",
       "      <td>0.859590</td>\n",
       "      <td>0.900709</td>\n",
       "      <td>0.925532</td>\n",
       "      <td>0.913412</td>\n",
       "      <td>0.024823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.941605</td>\n",
       "      <td>0.881579</td>\n",
       "      <td>0.890661</td>\n",
       "      <td>0.911348</td>\n",
       "      <td>0.950355</td>\n",
       "      <td>0.933987</td>\n",
       "      <td>0.039007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient Boost</td>\n",
       "      <td>0.673234</td>\n",
       "      <td>0.905921</td>\n",
       "      <td>0.599347</td>\n",
       "      <td>0.450355</td>\n",
       "      <td>0.879433</td>\n",
       "      <td>0.727450</td>\n",
       "      <td>0.429078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Name  Accuracy    Recall        F1    CV Min    CV Max  \\\n",
       "0  Logistic Rregression  0.943912  0.940789  0.900504  0.939502  0.968085   \n",
       "1                   KNN  0.725595  0.125658  0.198133  0.726950  0.765125   \n",
       "2         Random Forest  0.918530  0.924342  0.859590  0.900709  0.925532   \n",
       "3               XGBoost  0.941605  0.881579  0.890661  0.911348  0.950355   \n",
       "4        Gradient Boost  0.673234  0.905921  0.599347  0.450355  0.879433   \n",
       "\n",
       "    CV Mean  CV Range  \n",
       "0  0.949602  0.028583  \n",
       "1  0.743805  0.038174  \n",
       "2  0.913412  0.024823  \n",
       "3  0.933987  0.039007  \n",
       "4  0.727450  0.429078  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Appending the vanilla scores into Dataframe. \n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "After reviewing all baseline models, it is very clear that Logistic Regression is the best model overall, although Random Forest and XGBoost provided a great Accuracy, it does not compare with the results that came from Logistic Regression, but maybe there is room for improvement in all three. Gradient Boost do shows great promise if tis explored with GridSearch. I will further explore PCA and GridSearch to better Logistic Regression, Random Forest and Gradient boost. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Using PCA to help improve the Logistic Regression Model, PCA was chosen because can be used also as an interpretable model, this is important since we want to help the company lower the customer churn by looking at the features.\n",
    "\n",
    "Since we had a large dataset and was reduced to the most important features by using RFE, PCA could also help reduce the curse of dimensionality. The data, so far, has also not been scaled and will be for PCA since PCA requires the data to be in the same scale. For that we are using the StandardScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T17:46:28.923288Z",
     "start_time": "2021-01-02T17:46:28.905901Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Scaling & fitting training data and fitting the testing data.\n",
    "sc = StandardScaler()\n",
    "\n",
    "X_train_scaled = sc.fit_transform(X_train)\n",
    "X_test_scaled = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For PCA we want to reduce the number of components to 2. We want the model to be able to handle the dimensionality by using 2 components to explain the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T17:46:28.943563Z",
     "start_time": "2021-01-02T17:46:28.924844Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Creating 2 principal components\n",
    "pca=PCA(n_components=2)\n",
    "\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T17:46:28.956452Z",
     "start_time": "2021-01-02T17:46:28.945976Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Using the baseline Logistic Regression model for the PCA data.\n",
    "log_reg_pca=LogisticRegression(max_iter=1000, random_state=40)\n",
    "log_reg_pca.fit(X_train_pca,y_train)\n",
    "\n",
    "log_pred_pca=log_reg_pca.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T17:46:29.023704Z",
     "start_time": "2021-01-02T17:46:28.958920Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.8246983676366217\n",
      "Training Recall: 0.5730659025787965\n",
      "Training F1: 0.6182380216383306\n",
      "\n",
      "Logistic Regression with PCA Accuracy: 0.8186013489527867\n",
      "Logistic Regression with PCA Recall: 0.5730263157894737\n",
      "Logistic Regression with PCA F1: 0.6302460202604921\n",
      "\n",
      "Cross-Validation (5 times) Accuracy Scores:\n",
      "Min:  0.804965   Max:  0.85461   Mean:  0.825398   Range:  0.049645\n"
     ]
    }
   ],
   "source": [
    "scoring(log_pred_pca , \"Logistic Regression with PCA\", log_reg_pca, cv=5, xtrain=X_train_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T17:46:29.029409Z",
     "start_time": "2021-01-02T17:46:29.026089Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# scores_df #Uncomment to view table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "After comparing the PCA Logistic Regression with the baseline logistic regression, it clearly did not performed as  expected. Recall suffered as well as the F1 score, although CV does have a low range it doesn't look like there could be much improvement.In the end, it doesn't seem like the right path to take, specially since Accuracy is the most important metric for this model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Grid Search for Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "I decided to use GridSearch first on RandomForest to see if i am able to improve on the results that the baseline model brought. The parameters that were chosen to search are:\n",
    "* Max Depth with a range of 5 to 30. Although an extreme range, we want to check what penalty could be the best for such model.\n",
    "* Minimum Samples Leaf with a range of 1 to 5, by maintaining a low leaf node we make sure that the data is mostly evenly split and adds some bias to the model.\n",
    "* Minimum Samples Split with a range of 1 to 5, by maintaining a low split we make sure that the data is not fully overfit. \n",
    "* BootStrap to see the difference of having the combined the predictions from multiple machine learning algorithms together to make more accurate predictions or not having such predictions.\n",
    "* Class Weight \"Balanced\" and \"None\" to verify that having a \"Balanced\" data is the best option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T17:46:29.036269Z",
     "start_time": "2021-01-02T17:46:29.031964Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "params_RF={\n",
    "    \"max_depth\":range(5,30,5),\n",
    "    \"min_samples_leaf\":range(1,5,1),\n",
    "    \"min_samples_split\":range(1,5,1),\n",
    "    \"bootstrap\":[\"True\",\"False\"],\n",
    "    \"class_weight\":[\"None\",\"balanced\"]  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T17:46:29.042765Z",
     "start_time": "2021-01-02T17:46:29.038568Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "RF=RandomForestClassifier(random_state=40)\n",
    "grid_rf=GridSearchCV(RF, params_RF, cv=10, scoring=\"f1\", verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T17:47:40.683938Z",
     "start_time": "2021-01-02T17:46:29.045254Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 320 candidates, totalling 3200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1603 tasks      | elapsed:   36.2s\n",
      "[Parallel(n_jobs=-1)]: Done 2682 tasks      | elapsed:   50.0s\n",
      "[Parallel(n_jobs=-1)]: Done 3032 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 3200 out of 3200 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=RandomForestClassifier(random_state=40),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'bootstrap': ['True', 'False'],\n",
       "                         'class_weight': ['None', 'balanced'],\n",
       "                         'max_depth': range(5, 30, 5),\n",
       "                         'min_samples_leaf': range(1, 5),\n",
       "                         'min_samples_split': range(1, 5)},\n",
       "             scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T17:47:40.692593Z",
     "start_time": "2021-01-02T17:47:40.686715Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Gridsearch Score: 0.8960368756424364\n",
      "Best Parameters: {'bootstrap': 'True', 'class_weight': 'balanced', 'max_depth': 25, 'min_samples_leaf': 2, 'min_samples_split': 2}\n",
      "Best Estimators: RandomForestClassifier(bootstrap='True', class_weight='balanced', max_depth=25,\n",
      "                       min_samples_leaf=2, random_state=40)\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Gridsearch Score: {}\".format(grid_rf.best_score_))\n",
    "print(\"Best Parameters: {}\".format(grid_rf.best_params_))\n",
    "print(\"Best Estimators: {}\".format(grid_rf.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "It comes with no surprise that the model chose a Class Weight of Balanced as well as a Bootstrap of True. It is interesting that a max depth of 25 was chosen since its quite high but when it came to the Min Samples split and Leaf a lower number was chosen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T17:47:40.753754Z",
     "start_time": "2021-01-02T17:47:40.694723Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "grid_rf_pred=grid_rf.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T17:47:42.709595Z",
     "start_time": "2021-01-02T17:47:40.755468Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9971611071682044\n",
      "Training Recall: 0.994269340974212\n",
      "Training F1: 0.994269340974212\n",
      "\n",
      "Grid Search Random Forest Accuracy: 0.9508342208022719\n",
      "Grid Search Random Forest Recall: 0.8855263157894737\n",
      "Grid Search Random Forest F1: 0.9067025934658135\n",
      "\n",
      "Cross-Validation (10 times) Accuracy Scores:\n",
      "Min:  0.900709   Max:  0.971631   Mean:  0.950329   Range:  0.070922\n"
     ]
    }
   ],
   "source": [
    "scoring(grid_rf_pred , \"Grid Search Random Forest\", grid_rf, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T17:47:42.715351Z",
     "start_time": "2021-01-02T17:47:42.712576Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# scores_df#Uncomment to view table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Overall GridSearch did improve the Random Forest significantly, the Accuracy score did improve by 0.04 from the original Random forest, Recall took a hit but the F1 score stayed around the same. It seems that the model could be improved further but it does not compare to the original Logistic Regression scores that were pretty good from the getgo. Next I will explore Logistic Regression with Grid Search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Grid Search for Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "After not getting much improvement from PCA, maybe GridSearch could bring up the scores for Logistic Regression and make a better model by tunning specific parameters. \n",
    "\n",
    "For tunning parameters the ones used are:\n",
    "* Penalty of \"L1\" and \"L2\" since I want to compare both Ridge and Lasso as penalties to see if either one could best interpret the features.\n",
    "* Class Weight \"Balanced\" since there is high class imbalance in the data.\n",
    "* Max Iterations with a range of 1000 to 10000 to make sure the model is able to converge.\n",
    "* Warm Start \"True\" and \"False\" to compare how can a warm start benefit the CV process. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T17:47:42.721464Z",
     "start_time": "2021-01-02T17:47:42.717786Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Choosing Parameter for the model.\n",
    "params_lg={\n",
    "    \"penalty\":[\"l1\",\"l2\"],\n",
    "    \"class_weight\":[\"balanced\"],\n",
    "    \"max_iter\":range(1000,10000,100),\n",
    "    \"warm_start\":[\"True\",\"False\"]   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T17:47:42.728275Z",
     "start_time": "2021-01-02T17:47:42.724084Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# using vanilla Logistic Regression model and keeping the Random state for continuity and reproducibility\n",
    "log_reg=LogisticRegression(random_state=40)\n",
    "grid_lg=GridSearchCV(log_reg, params_lg, cv=5, scoring=\"accuracy\", verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T17:55:24.455423Z",
     "start_time": "2021-01-02T17:47:42.730585Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 360 candidates, totalling 1800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done 224 tasks      | elapsed:   14.7s\n",
      "[Parallel(n_jobs=-1)]: Done 474 tasks      | elapsed:   46.0s\n",
      "[Parallel(n_jobs=-1)]: Done 824 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1274 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1800 out of 1800 | elapsed:  7.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(random_state=40), n_jobs=-1,\n",
       "             param_grid={'class_weight': ['balanced'],\n",
       "                         'max_iter': range(1000, 10000, 100),\n",
       "                         'penalty': ['l1', 'l2'],\n",
       "                         'warm_start': ['True', 'False']},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_lg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T17:55:24.462156Z",
     "start_time": "2021-01-02T17:55:24.457547Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Gridsearch Score: 0.9510234471618586\n",
      "Best Parameters: {'class_weight': 'balanced', 'max_iter': 9400, 'penalty': 'l2', 'warm_start': 'True'}\n",
      "Best Estimators: LogisticRegression(class_weight='balanced', max_iter=9400, random_state=40,\n",
      "                   warm_start='True')\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Gridsearch Score: {}\".format(grid_lg.best_score_))\n",
    "print(\"Best Parameters: {}\".format(grid_lg.best_params_))\n",
    "print(\"Best Estimators: {}\".format(grid_lg.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "It seemed that Ridge was the best at keeping the relevant features for the model to perform optimally. It came as no surprise that balancing the class is the best way to have a model improve but it seems that the max iterations was loser to the max of the range and this could be improved in the second iteration of GridSearch with the tunned parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T17:55:24.471464Z",
     "start_time": "2021-01-02T17:55:24.464936Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gs_pred=grid_lg.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T17:55:37.538088Z",
     "start_time": "2021-01-02T17:55:24.473739Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9623846699787083\n",
      "Training Recall: 0.9742120343839542\n",
      "Training F1: 0.927694406548431\n",
      "\n",
      "Grid Search Logistic Regression Accuracy: 0.9440894568690096\n",
      "Grid Search Logistic Regression Recall: 0.9414473684210526\n",
      "Grid Search Logistic Regression F1: 0.9008498583569404\n",
      "\n",
      "Cross-Validation (5 times) Accuracy Scores:\n",
      "Min:  0.932384   Max:  0.968085   Mean:  0.950307   Range:  0.035701\n"
     ]
    }
   ],
   "source": [
    "scoring(gs_pred , \"Grid Search Logistic Regression\", grid_lg, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T17:55:37.543119Z",
     "start_time": "2021-01-02T17:55:37.540474Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# scores_df#Uncomment to view table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This model shows improvement although its a minimal improvement by using the best parameters and adding more tunning it will provide the best model for predicting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Grid Search for Logistic Regression (Best Params) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now that we ran our first GridSearch, I will use the best parameter for the second run. Here I added more tunning to the already set parameters.\n",
    "\n",
    "* C of 1 and 5. to see which value of C could to disincentivize and regulate against Overfitting.\n",
    "* Max Iterations with a range of 9000 to 10000 since the previous iteration of GridSearch found the value to be 9400 and now, I want to explore a more detail range. \n",
    "* Solver of \"lbfgs\" and \"Sags\" since lbfgs is the default solver, I'd like to compare it with Sags since its more beneficial for larger datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T17:55:37.549583Z",
     "start_time": "2021-01-02T17:55:37.545946Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Choosing Parameter for the model.\n",
    "params={\n",
    "    \"C\":[1,5],\n",
    "    \"max_iter\":range(9000,10000,10),\n",
    "    \"solver\":['lbfgs', 'sags']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T17:55:37.555934Z",
     "start_time": "2021-01-02T17:55:37.551920Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# using vanilla Logistic Regression model and keeping the Random state for continuity and reproducibility\n",
    "log_reg2= LogisticRegression(class_weight='balanced', random_state=40, warm_start='True')\n",
    "grid_lg2=GridSearchCV(log_reg2, params, cv=5, scoring=\"f1\", verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-02T17:45:57.778Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 400 candidates, totalling 2000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed:   20.3s\n",
      "[Parallel(n_jobs=-1)]: Done 200 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 450 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 800 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1250 tasks      | elapsed:  9.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1800 tasks      | elapsed: 13.8min\n"
     ]
    }
   ],
   "source": [
    "grid_lg2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-02T17:45:57.779Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(\"Best Gridsearch Score: {}\".format(grid_lg2.best_score_))\n",
    "print(\"Best Parameters: {}\".format(grid_lg2.best_params_))\n",
    "print(\"Best Estimators: {}\".format(grid_lg2.best_estimator_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-02T17:45:57.781Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gs_pred2=grid_lg2.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-02T17:45:57.782Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scoring(gs_pred2 , \"Grid Search Logistic Regression 2\", grid_lg2, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-02T17:45:57.784Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# scores_df #Uncomment to view table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Gridsearch Gradient Boost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Lastly I want to explore Gradient Boost. Gradient boost seemed the most promising since it's scores seemed a bit erratic. I believe with a bit of tunning it could show much improvement. The tunning parameters or Gradient boosting are\":\n",
    "\n",
    "* Min Samples Split with a range of 2 to 10, I want to see if a lower or higher value could return a better score. \n",
    "* Max Depth with a range of 1 to 5, by maintaining lower scores to reduce overfitting. \n",
    "* Max Features with \"Auto\", \"Sqrt\" and \"Log 2\" to see witch of the exponential number of features to consider when looking for the best split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-02T17:45:57.786Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Choosing Parameter for the model.\n",
    "params_gb={\n",
    "    \"min_samples_split\" : range(2,10,1),\n",
    "    \"max_depth\" : range(1,5,1),\n",
    "    \"max_features\" : ['auto', 'sqrt', 'log2']   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-02T17:45:57.788Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# using vanilla Logistic Regression model and keeping the Random state for continuity and reproducibility\n",
    "gb = GradientBoostingClassifier(random_state=40)\n",
    "grid_gb=GridSearchCV(gb, params_gb, cv=5, scoring=\"accuracy\", verbose=1, n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-02T17:45:57.789Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "grid_gb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-02T17:45:57.791Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Best Gridsearch Score: {}\".format(grid_gb.best_score_))\n",
    "print(\"Best Parameters: {}\".format(grid_gb.best_params_))\n",
    "print(\"Best Estimators: {}\".format(grid_gb.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Interestingly, the best params for Max Depth and Min Samples Split are on the higher end of the range that was provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-02T17:45:57.793Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "grid_gb_pred=grid_gb.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-02T17:45:57.794Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "scoring(grid_gb_pred , \"Grid Search Gradient Boost\", grid_gb, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-02T17:45:57.796Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# scores_df #Uncomment to view table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This model model has performed the best out of all the models that have been explored. With great Accuracy and F1 score, although Recall took a hit it could be improved in the next round of Gridsearch. Looking at the CV scores, the range is very low which is good since all the folds have around the same value of the test score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-27T21:36:40.177536Z",
     "start_time": "2020-12-27T21:36:40.168295Z"
    }
   },
   "source": [
    "### Gridsearch Gradient Boost Best Params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we see how good the results we got after Gridsearch, the best parameters were implemented to the second round of Gridsearch. Now the new parameters to tune were added:\n",
    "\n",
    "* Loss of \"Deviance\" and \"Exponential\" \"Deviance\" refers to deviance (= logistic regression) for classification with probabilistic outputs. For loss \"Exponential\" gradient boosting recovers the AdaBoost algorithm.\n",
    "* Learning Rate of range 0.1 to 5 to shrink the contribution of each tree by learning_rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-02T17:45:57.798Z"
    }
   },
   "outputs": [],
   "source": [
    "params_gb2={\n",
    "   \"loss\" : ['deviance', 'exponential'],\n",
    "   \"learning_rate\" : np.arange(0.1,5,0.1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-02T17:45:57.800Z"
    }
   },
   "outputs": [],
   "source": [
    "gb =  GradientBoostingClassifier(max_depth=4, max_features='sqrt', min_samples_split=9, random_state=40)\n",
    "grid_gb2=GridSearchCV(gb, params_gb2, cv=5, scoring=\"accuracy\", verbose=1, n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-02T17:45:57.801Z"
    }
   },
   "outputs": [],
   "source": [
    "grid_gb2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-02T17:45:57.803Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Best Gridsearch Score: {}\".format(grid_gb2.best_score_))\n",
    "print(\"Best Parameters: {}\".format(grid_gb2.best_params_))\n",
    "print(\"Best Estimators: {}\".format(grid_gb2.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It came to no surprise that the learning rate came out to 1.1 since 1 is the optimal value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-02T17:45:57.805Z"
    }
   },
   "outputs": [],
   "source": [
    "grid_gb_pred2=grid_gb2.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-02T17:45:57.807Z"
    }
   },
   "outputs": [],
   "source": [
    "scoring(grid_gb_pred2 , \"Grid Search Gradient Boost 2\", grid_gb2, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-02T17:45:57.808Z"
    }
   },
   "outputs": [],
   "source": [
    "# scores_df #Uncomment to view table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall this model came out with the best scores overall. With great Accuracy and F1, as well as an improved Recall, we could see this model performing great specially after looking at the CV scores since they seem to be with minimal difference in each fold. The only concerning part is that the Training scores are Overfit, this could be mitigated by some more regularization but overall after comparing the CV and the final scores it seems that this can be the final model for the company's churn algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we can find a graph with each result. We see that the model did a great job overall at predicting each category. Although we have a high False Negative, we mostly wanted to focus on our False Positive since we want to mitigate the company focusing resources to customers who are predicted to churn when they're actually not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-02T17:45:57.827Z"
    }
   },
   "outputs": [],
   "source": [
    "pred = confusion_matrix(y_test, grid_gb_pred2)\n",
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "sns.heatmap(pred.T, square=True, annot=True, fmt='d',cmap=\"PuBu\", cbar=False,\n",
    "            xticklabels=['Stayed', 'Churned'], yticklabels=['Stayed', 'Churned'])\n",
    "sns.set(font_scale=2)\n",
    "plt.xlabel('True Values',fontsize=20)\n",
    "plt.ylabel('Predicted Values',fontsize=20);\n",
    "plt.savefig('/Users/carlosruiz/Desktop/Mod_5_project/Images/matrix', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, GridSearch with Logistic Gradient Boost proved the best model at predicting Accuracy and F1. By using this model assures that all predictions would be accurate and the company can focus on customer that are possibly churning or have churned and base their attention in recovering them or bettering their services to maintain their customer base. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-02T17:45:57.829Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating a DF with the coeficients for each feature for futher visualiztions.\n",
    "coef=pd.DataFrame(zip(X_train.columns, np.transpose(grid_lg.best_estimator_.coef_[0])), columns=['features', 'coef'])\n",
    "coef.iloc[list(coef.coef.sort_values(ascending=False).index)].reset_index(drop=True,inplace=True)\n",
    "coef.to_csv(\"coeficient.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the visualization of Gradient Boost coefficients please go to the [Visualizations Notebook](Visualizations_Notebook.ipynb) to view the EDA process go to the [EDA Notebook](EDA_Notebook.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
